{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "dotenv.load_dotenv()\n",
    "llm = AzureChatOpenAI(\n",
    "    model=os.environ['COMPLETIONS_MODEL'],  # or your deployment\n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    #azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],  # or your api version\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore programmer.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 31, 'total_tokens': 37, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_5b26d85e12', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-9ba3c353-217c-4034-ae80-75a7489985ef-0', usage_metadata={'input_tokens': 31, 'output_tokens': 6, 'total_tokens': 37, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_intro.chatbot import llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q langchain openai langchain-community langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "         content=\"\"\"You're an assistant knowledgeable about\n",
    "        healthcare. Only answer healthcare-related questions.\"\"\"\n",
    "  ),\n",
    "    HumanMessage(content=\"What is Medicaid managed care?\"),\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Medicaid Managed Care is a system where Medicaid recipients receive their health care services through an organized network of healthcare providers. This system is designed to improve the quality of care and reduce healthcare costs by coordinating care and providing services in a more efficient manner. Managed care organizations (MCOs) contract with state Medicaid agencies to provide a range of health services to enrolled members at a set per-member per-month payment rate.\\n\\nIn this model, Medicaid beneficiaries are typically required to choose or are assigned to a specific managed care plan. These plans often include services such as primary care, hospital services, prescription drugs, and sometimes additional benefits like dental and vision care. The goal is to provide comprehensive, coordinated care that addresses a wide range of health needs, potentially improving outcomes and patient satisfaction while controlling costs.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 157, 'prompt_tokens': 33, 'total_tokens': 190, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_5b26d85e12', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-3a37aa01-d27b-4dcd-8680-b52d1148aedc-0', usage_metadata={'input_tokens': 33, 'output_tokens': 157, 'total_tokens': 190, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "         content=\"\"\"You're an assistant knowledgeable about\n",
    "        healthcare. Only answer healthcare-related questions.\"\"\"\n",
    "  ),\n",
    "    HumanMessage(content=\"How do I change a tire?\"),\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm here to help with healthcare-related questions. If you have any inquiries about health, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 34, 'total_tokens': 57, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_5b26d85e12', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-aaffa6b6-3bc3-46ea-9dac-0d178ad111e8-0', usage_metadata={'input_tokens': 34, 'output_tokens': 23, 'total_tokens': 57, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Changing a flat tire can be a straightforward process if you have the right tools and follow these steps:\\n\\n1. Find a safe location: As soon as you realize you have a flat tire, do not abruptly brake or turn. Slowly reduce speed and scan your surroundings for a level, straight stretch of road with a wide shoulder. An empty parking lot would be an ideal place.\\n\\n2. Turn on your hazard lights: This will let other drivers know you have an issue and are slowing down.\\n\\n3. Apply the parking brake: This will minimize the possibility of your vehicle rolling.\\n\\n4. Apply wheel wedges: Place these in front of or behind the tires to further ensure the vehicle doesn’t roll while you fix the flat tire.\\n\\n5. Remove the wheel cover or hubcap: If your tire has a hubcap covering the lug nuts, it’s easier to remove the hubcap before lifting the vehicle with the jack. Use the flat end of your lug wrench to remove the hubcap.\\n\\n6. Loosen the lug nuts: Using the lug wrench, turn the lug nuts counterclockwise until you break their resistance. You may have to use force, and that’s okay. Loosen them about ¼ to ½ of a turn, but do not remove them completely yet.\\n\\n7. Place the jack under the vehicle: The right place for the jack is usually beneath the vehicle frame alongside the tire that’s flat. Many vehicle frames have molded plastic on the bottom with a cleared area of exposed metal specifically for the jack. Raise the jack until it is supporting (but not lifting) the car.\\n\\n8. Raise the vehicle with the jack: Pump or crank the jack to lift the tire off the ground. You need to lift it high enough to remove the flat tire and replace it with a spare.\\n\\n9. Unscrew the lug nuts: Now it’s time to remove the lug nuts all the way. Since you've already loosened them, you should be able to unscrew them mostly by hand.\\n\\n10. Remove the flat tire: Grip the tire by the treads and pull it gently toward you until it’s completely free from the hub behind it. Set it on its side so that it doesn’t roll away.\\n\\n11. Mount the spare tire on the lug bolts: Now place the spare on the hub by lining up the rim with the lug bolts. Push gently until the lug bolts show through the rim.\\n\\n12. Tighten the lug nuts by hand: Put the lug nuts back on the lug bolts and tighten them all the way by hand. Once they are all on, check each one again, tightening as much as possible.\\n\\n13. Lower the vehicle and tighten the lug nuts again: Use the jack to lower the vehicle so that the spare tire is resting on the ground but the full weight of the vehicle isn’t fully on the tire. At this point, you should tighten the lug nuts with the wrench, turning clockwise, as much as you can.\\n\\n14. Lower the vehicle completely: Bring the vehicle all the way to the ground and remove the jack. Give the lug nuts another pull with the wrench to ensure they’re as tight as possible.\\n\\n15. Replace the hubcap: If the hubcap you took from the flat tire will fit your spare, put it in place the same way you took it off. If it doesn’t fit, stow it away with the tire when you stow your equipment.\\n\\n16. Stow all equipment: You have before you drive away, make sure to put all your tools and the flat tire into your vehicle.\\n\\n17. Check the pressure in the spare tire: To ensure safety, check that the spare tire is inflated properly as soon as possible.\\n\\n18. Take your flat tire to a technician: Temporary spare tires aren’t made to drive long distances or at high speeds, so drive cautiously until you’re able to visit a tire technician.\\n\\nChanging a tire is a skill that can save you time and money. Make sure to practice this skill to get better at it.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 812, 'prompt_tokens': 14, 'total_tokens': 826, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_5b26d85e12', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-99f70199-66f7-48ea-98b9-1dab9b104cb0-0', usage_metadata={'input_tokens': 14, 'output_tokens': 812, 'total_tokens': 826, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how to I change flat typre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_str = \"\"\"Your job is to use patient\n",
    "... reviews to answer questions about their experience at a hospital.\n",
    "... Use the following context to answer questions. Be as detailed\n",
    "... as possible, but don't make up any information that's not\n",
    "... from the context. If you don't know an answer, say you don't know.\n",
    "...\n",
    "... {context}\n",
    "...\n",
    "... {question}\n",
    "... \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your job is to use patient\\nreviews to answer questions about their experience at a hospital.\\nUse the following context to answer questions. Be as detailed\\nas possible, but don't make up any information that's not\\nfrom the context. If you don't know an answer, say you don't know.\\n\\n{context}\\n\\n{question}\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_template_str.replace(\"...\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your job is to use patient\\nreviews to answer questions about their experience at a hospital.\\nUse the following context to answer questions. Be as detailed\\nas possible, but don't make up any information that's not\\nfrom the context. If you don't know an answer, say you don't know.\\n\\n{context}\\n\\n{question}\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_template_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template = ChatPromptTemplate.from_template(review_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Your job is to use patient\\nreviews to answer questions about their experience at a hospital.\\nUse the following context to answer questions. Be as detailed\\nas possible, but don't make up any information that's not\\nfrom the context. If you don't know an answer, say you don't know.\\n\\n{context}\\n\\n{question}\\n\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"I had a great stay!\"\n",
    "question = \"Did anyone have a positive experience?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Your job is to use patient\\nreviews to answer questions about their experience at a hospital.\\nUse the following context to answer questions. Be as detailed\\nas possible, but don't make up any information that's not\\nfrom the context. If you don't know an answer, say you don't know.\\n\\nI had a great stay!\\n\\nDid anyone have a positive experience?\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_template.format(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=review_template | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=output.invoke({\"context\": context, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the patient had a positive experience, as indicated by their review stating, \"I had a great stay!\"'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (2.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from pydantic) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from pydantic) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000191EB03D3F0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000191EB03F4F0>, root_client=<openai.lib.azure.AzureOpenAI object at 0x00000191E72961D0>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x00000191EB03D450>, model_name='gpt-4-turbo', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), disabled_params={'parallel_tool_calls': None}, azure_endpoint='https://cnxdev.openai.azure.com', openai_api_version='2024-02-15-preview', openai_api_type='azure')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Joke' has no attribute 'model_json_schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m      2\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer the user query.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{format_instructions}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{query}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m----> 4\u001b[0m     partial_variables\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_instructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_format_instructions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m},\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Generate and parse output\u001b[39;00m\n\u001b[0;32m      8\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat(query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me a joke.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\medical_chatbot\\Hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:92\u001b[0m, in \u001b[0;36mPydanticOutputParser.get_format_instructions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the format instructions for the JSON output.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m    The format instructions for the JSON output.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Copy schema to avoid altering original Pydantic schema.\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpydantic_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_json_schema\u001b[49m()\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Remove extraneous fields.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m reduced_schema \u001b[38;5;241m=\u001b[39m schema\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Joke' has no attribute 'model_json_schema'"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Generate and parse output\n",
    "formatted_prompt = prompt.format(query=\"Tell me a joke.\")\n",
    "output = llm(formatted_prompt)\n",
    "parsed_output = parser.parse(output.content)\n",
    "\n",
    "print(parsed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from chromadb) (2.10.3)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.20.1-cp310-cp310-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.20.3-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.68.1-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.2.1-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from chromadb) (3.10.12)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting importlib-metadata>=4.6 (from build>=1.0.3->chromadb)\n",
      "  Using cached importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Using cached starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.29.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading wrapt-1.17.0-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers<=0.20.3,>=0.13.2->chromadb)\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.0-cp310-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-14.1-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=4.6->build>=1.0.3->chromadb)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\medical_chatbot\\hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
      "   ---------------------------------------- 0.0/628.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 628.3/628.3 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl (150 kB)\n",
      "Using cached bcrypt-4.2.1-cp39-abi3-win_amd64.whl (153 kB)\n",
      "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "Downloading grpcio-1.68.1-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.8/4.4 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.9/4.4 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.7/4.4 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 5.3 MB/s eta 0:00:00\n",
      "Using cached kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Downloading mmh3-5.0.1-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Downloading onnxruntime-1.20.1-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.3 MB 6.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.3 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/11.3 MB 6.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.3 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.3 MB 5.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.0/11.3 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.3 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.1/11.3 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.3/11.3 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.6/11.3 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.9/11.3 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.1/11.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.9/11.3 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.0/11.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.5/11.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 2.7 MB/s eta 0:00:00\n",
      "Using cached opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
      "Using cached opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\n",
      "Using cached opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
      "Using cached opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading tokenizers-0.20.3-cp310-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Using cached durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Using cached google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Downloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading protobuf-5.29.1-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Downloading watchfiles-1.0.0-cp310-none-win_amd64.whl (285 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-14.1-cp310-cp310-win_amd64.whl (163 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.2 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.4/6.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.4/6.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 3.9 MB/s eta 0:00:00\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading wrapt-1.17.0-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pypika, mpmath, monotonic, flatbuffers, durationpy, zipp, wrapt, websockets, websocket-client, tomli, sympy, shellingham, pyreadline3, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, fsspec, filelock, click, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, humanfriendly, huggingface-hub, googleapis-common-protos, deprecated, tokenizers, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, fastapi, coloredlogs, build, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 cachetools-5.5.0 chroma-hnswlib-0.7.6 chromadb-0.5.23 click-8.1.7 coloredlogs-15.0.1 deprecated-1.2.15 durationpy-0.9 fastapi-0.115.6 filelock-3.16.1 flatbuffers-24.3.25 fsspec-2024.10.0 google-auth-2.36.0 googleapis-common-protos-1.66.0 grpcio-1.68.1 httptools-0.6.4 huggingface-hub-0.26.5 humanfriendly-10.0 importlib-metadata-8.5.0 importlib-resources-6.4.5 kubernetes-31.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.0.1 monotonic-1.6 mpmath-1.3.0 oauthlib-3.2.2 onnxruntime-1.20.1 opentelemetry-api-1.28.2 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-sdk-1.28.2 opentelemetry-semantic-conventions-0.49b2 opentelemetry-util-http-0.49b2 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.1 pyasn1-0.6.1 pyasn1-modules-0.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-13.9.4 rsa-4.9 shellingham-1.5.4 starlette-0.41.3 sympy-1.13.3 tokenizers-0.20.3 tomli-2.2.1 typer-0.15.1 uvicorn-0.32.1 watchfiles-1.0.0 websocket-client-1.8.0 websockets-14.1 wrapt-1.17.0 zipp-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEWS_CHROMA_PATH = \"chroma_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\medical_chatbot\\\\Hospital_chatbot'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmanoj\\AppData\\Local\\Temp\\ipykernel_4928\\3481142159.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  reviews_vector_db = Chroma(\n"
     ]
    }
   ],
   "source": [
    "reviews_vector_db = Chroma(\n",
    "     persist_directory=REVIEWS_CHROMA_PATH,\n",
    "     embedding_function=AzureOpenAIEmbeddings(), \n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Has anyone complained about\n",
    "            communication with the hospital staff?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = reviews_vector_db.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'row': 416, 'source': 'I had a frustrating experience at the hospital. The communication between the medical staff and me was unclear, leading to misunderstandings about my treatment plan. Improvement is needed in this area.'}, page_content='review_id: 73\\nvisit_id: 7696\\nreview: I had a frustrating experience at the hospital. The communication between the medical staff and me was unclear, leading to misunderstandings about my treatment plan. Improvement is needed in this area.\\nphysician_name: Maria Thompson\\nhospital_name: Little-Spencer\\npatient_name: Terri Smith'),\n",
       " Document(metadata={'row': 253, 'source': 'The hospital staff was professional and caring, making my stay as comfortable as possible. However, the lack of communication about the potential side effects of my medication was concerning.'}, page_content='review_id: 120\\nvisit_id: 4804\\nreview: The hospital staff was professional and caring, making my stay as comfortable as possible. However, the lack of communication about the potential side effects of my medication was concerning.\\nphysician_name: Lisa Brewer\\nhospital_name: Wheeler, Bryant and Johns\\npatient_name: Hannah Cruz'),\n",
       " Document(metadata={'row': 758, 'source': 'My stay at the hospital was challenging. The medical care was adequate, but the lack of communication from the staff created some frustration.'}, page_content='review_id: 785\\nvisit_id: 2593\\nreview: My stay at the hospital was challenging. The medical care was adequate, but the lack of communication from the staff created some frustration.\\nphysician_name: Brittany Harris\\nhospital_name: Jones, Taylor and Garcia\\npatient_name: Ryan Jacobs')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- ---------------\n",
      "aiohappyeyeballs                         2.4.4\n",
      "aiohttp                                  3.11.10\n",
      "aiosignal                                1.3.1\n",
      "annotated-types                          0.7.0\n",
      "anyio                                    4.7.0\n",
      "asgiref                                  3.8.1\n",
      "asttokens                                3.0.0\n",
      "async-timeout                            4.0.3\n",
      "attrs                                    24.2.0\n",
      "backoff                                  2.2.1\n",
      "bcrypt                                   4.2.1\n",
      "build                                    1.2.2.post1\n",
      "cachetools                               5.5.0\n",
      "certifi                                  2024.8.30\n",
      "charset-normalizer                       3.4.0\n",
      "chroma-hnswlib                           0.7.6\n",
      "chromadb                                 0.5.23\n",
      "click                                    8.1.7\n",
      "colorama                                 0.4.6\n",
      "coloredlogs                              15.0.1\n",
      "comm                                     0.2.2\n",
      "dataclasses-json                         0.6.7\n",
      "debugpy                                  1.8.9\n",
      "decorator                                5.1.1\n",
      "Deprecated                               1.2.15\n",
      "distro                                   1.9.0\n",
      "durationpy                               0.9\n",
      "exceptiongroup                           1.2.2\n",
      "executing                                2.1.0\n",
      "fastapi                                  0.115.6\n",
      "filelock                                 3.16.1\n",
      "flatbuffers                              24.3.25\n",
      "frozenlist                               1.5.0\n",
      "fsspec                                   2024.10.0\n",
      "google-auth                              2.36.0\n",
      "googleapis-common-protos                 1.66.0\n",
      "greenlet                                 3.1.1\n",
      "grpcio                                   1.68.1\n",
      "h11                                      0.14.0\n",
      "httpcore                                 1.0.7\n",
      "httptools                                0.6.4\n",
      "httpx                                    0.28.1\n",
      "httpx-sse                                0.4.0\n",
      "huggingface-hub                          0.26.5\n",
      "humanfriendly                            10.0\n",
      "idna                                     3.10\n",
      "importlib_metadata                       8.5.0\n",
      "importlib_resources                      6.4.5\n",
      "ipykernel                                6.29.5\n",
      "ipython                                  8.30.0\n",
      "jedi                                     0.19.2\n",
      "jiter                                    0.8.2\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              3.0.0\n",
      "jupyter_client                           8.6.3\n",
      "jupyter_core                             5.7.2\n",
      "kubernetes                               31.0.0\n",
      "langchain                                0.3.10\n",
      "langchain-community                      0.3.10\n",
      "langchain-core                           0.3.22\n",
      "langchain-openai                         0.2.12\n",
      "langchain-text-splitters                 0.3.2\n",
      "langchainhub                             0.1.21\n",
      "langsmith                                0.1.147\n",
      "markdown-it-py                           3.0.0\n",
      "marshmallow                              3.23.1\n",
      "matplotlib-inline                        0.1.7\n",
      "mdurl                                    0.1.2\n",
      "mmh3                                     5.0.1\n",
      "monotonic                                1.6\n",
      "mpmath                                   1.3.0\n",
      "multidict                                6.1.0\n",
      "mypy-extensions                          1.0.0\n",
      "nest-asyncio                             1.6.0\n",
      "numpy                                    1.26.4\n",
      "oauthlib                                 3.2.2\n",
      "onnxruntime                              1.20.1\n",
      "openai                                   1.57.1\n",
      "opentelemetry-api                        1.28.2\n",
      "opentelemetry-exporter-otlp-proto-common 1.28.2\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.28.2\n",
      "opentelemetry-instrumentation            0.49b2\n",
      "opentelemetry-instrumentation-asgi       0.49b2\n",
      "opentelemetry-instrumentation-fastapi    0.49b2\n",
      "opentelemetry-proto                      1.28.2\n",
      "opentelemetry-sdk                        1.28.2\n",
      "opentelemetry-semantic-conventions       0.49b2\n",
      "opentelemetry-util-http                  0.49b2\n",
      "orjson                                   3.10.12\n",
      "overrides                                7.7.0\n",
      "packaging                                24.2\n",
      "parso                                    0.8.4\n",
      "pip                                      24.2\n",
      "platformdirs                             4.3.6\n",
      "posthog                                  3.7.4\n",
      "prompt_toolkit                           3.0.48\n",
      "propcache                                0.2.1\n",
      "protobuf                                 5.29.1\n",
      "psutil                                   6.1.0\n",
      "pure_eval                                0.2.3\n",
      "pyasn1                                   0.6.1\n",
      "pyasn1_modules                           0.4.1\n",
      "pydantic                                 2.10.3\n",
      "pydantic_core                            2.27.1\n",
      "pydantic-settings                        2.6.1\n",
      "Pygments                                 2.18.0\n",
      "PyPika                                   0.48.9\n",
      "pyproject_hooks                          1.2.0\n",
      "pyreadline3                              3.5.4\n",
      "python-dateutil                          2.9.0.post0\n",
      "python-dotenv                            1.0.1\n",
      "pywin32                                  308\n",
      "PyYAML                                   6.0.2\n",
      "pyzmq                                    26.2.0\n",
      "regex                                    2024.11.6\n",
      "requests                                 2.32.3\n",
      "requests-oauthlib                        2.0.0\n",
      "requests-toolbelt                        1.0.0\n",
      "rich                                     13.9.4\n",
      "rsa                                      4.9\n",
      "setuptools                               75.1.0\n",
      "shellingham                              1.5.4\n",
      "six                                      1.17.0\n",
      "sniffio                                  1.3.1\n",
      "SQLAlchemy                               2.0.36\n",
      "stack-data                               0.6.3\n",
      "starlette                                0.41.3\n",
      "sympy                                    1.13.3\n",
      "tenacity                                 9.0.0\n",
      "tiktoken                                 0.8.0\n",
      "tokenizers                               0.20.3\n",
      "tomli                                    2.2.1\n",
      "tornado                                  6.4.2\n",
      "tqdm                                     4.67.1\n",
      "traitlets                                5.14.3\n",
      "typer                                    0.15.1\n",
      "types-requests                           2.32.0.20241016\n",
      "typing_extensions                        4.12.2\n",
      "typing-inspect                           0.9.0\n",
      "urllib3                                  2.2.3\n",
      "uvicorn                                  0.32.1\n",
      "watchfiles                               1.0.0\n",
      "wcwidth                                  0.2.13\n",
      "websocket-client                         1.8.0\n",
      "websockets                               14.1\n",
      "wheel                                    0.44.0\n",
      "wrapt                                    1.17.0\n",
      "yarl                                     1.18.3\n",
      "zipp                                     3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_intro.chatbot import review_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Has anyone complained about\n",
    "        communication with the hospital staff?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, several patients have complained about communication issues with the hospital staff. Here are the details:\\n\\n1. Terri Smith had a frustrating experience at Little-Spencer hospital due to unclear communication between the medical staff and herself, leading to misunderstandings about her treatment plan.\\n\\n2. Ryan Jacobs mentioned that his stay at Jones, Taylor and Garcia hospital was challenging because the lack of communication from the staff created some frustration.\\n\\n3. Hannah Cruz reported that while the hospital staff at Wheeler, Bryant and Johns was professional and caring, the lack of communication about the potential side effects of her medication was concerning.\\n\\n4. Kurt Gordon experienced a challenging time at Richardson-Powell hospital because the lack of communication between the staff and him left him feeling frustrated and confused about his treatment plan.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The best review about the hospital comes from Jose Johnson, who visited Burch-White hospital. He mentioned that the hospital provided top-notch medical care, and the facilities were modern and clean. He also highlighted that the entire staff, from doctors to janitors, contributed to a positive and comfortable environment. This review indicates a high level of satisfaction with both the medical care and the facilities.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_chain.invoke(\"what is the best review about the Hospital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\medical_chatbot\\Hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'hospital_agent_executor' from 'langchain_intro.chatbot' (c:\\medical_chatbot\\Hospital_chatbot\\langchain_intro\\chatbot.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_intro\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchatbot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hospital_agent_executor\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'hospital_agent_executor' from 'langchain_intro.chatbot' (c:\\medical_chatbot\\Hospital_chatbot\\langchain_intro\\chatbot.py)"
     ]
    }
   ],
   "source": [
    "from langchain_intro.chatbot import hospital_agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000024A59D81F30>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000024A59D81F30>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but the information provided does not include any details about changing a bike. If you have any other questions related to the hospital experiences mentioned in the reviews, feel free to ask!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_chain.invoke(\"How to change bike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\medical_chatbot\\Hospital_chatbot\\langchain_intro\\env3.10\\lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_intro.chatbot import hospital_agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can help you find out what patients think about a specific aspect of a hospital or their overall experiences. Could you please specify the hospital or the particular aspect of the hospital services you are interested in learning about?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res=hospital_agent_executor.invoke({\"input\": \"What best review out of all\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current wait time at Hospital C is 9144 minutes.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.get('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Reviews` with `What have patients said about their comfort at the hospital?`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPatients have had mixed experiences regarding their comfort at the hospital. One patient, Jasmine Patel DDS, had a positive experience, noting that the hospital's dedication to patient comfort was evident in the well-designed private rooms and comfortable furnishings, which made her recovery more bearable. However, other patients like Tammy Benson DVM, Crystal Johnson, and Nancy Collins reported discomfort due to the beds. Tammy Benson DVM and Crystal Johnson mentioned that the uncomfortable beds made it difficult to get a good night's sleep during their stay. Nancy Collins also pointed out that the outdated and uncomfortable beds affected her overall comfort, despite the hospital having knowledgeable doctors and a clean environment.\u001b[0m\u001b[32;1m\u001b[1;3mPatients have had mixed experiences regarding their comfort at the hospital. Some patients, like Jasmine Patel DDS, appreciated the well-designed private rooms and comfortable furnishings, which enhanced their recovery experience. However, others like Tammy Benson DVM, Crystal Johnson, and Nancy Collins reported discomfort due to the beds, mentioning that the uncomfortable beds made it difficult to get a good night's sleep and affected their overall comfort during their stay.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What have patients said about their comfort at the hospital?',\n",
       " 'output': \"Patients have had mixed experiences regarding their comfort at the hospital. Some patients, like Jasmine Patel DDS, appreciated the well-designed private rooms and comfortable furnishings, which enhanced their recovery experience. However, others like Tammy Benson DVM, Crystal Johnson, and Nancy Collins reported discomfort due to the beds, mentioning that the uncomfortable beds made it difficult to get a good night's sleep and affected their overall comfort during their stay.\",\n",
       " 'intermediate_steps': [(AgentActionMessageLog(tool='Reviews', tool_input='What have patients said about their comfort at the hospital?', log='\\nInvoking: `Reviews` with `What have patients said about their comfort at the hospital?`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"What have patients said about their comfort at the hospital?\"}', 'name': 'Reviews'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_5b26d85e12'}, id='run-4c5041c5-3f53-4cfa-b0fd-36d78e0ad08f')]),\n",
       "   \"Patients have had mixed experiences regarding their comfort at the hospital. One patient, Jasmine Patel DDS, had a positive experience, noting that the hospital's dedication to patient comfort was evident in the well-designed private rooms and comfortable furnishings, which made her recovery more bearable. However, other patients like Tammy Benson DVM, Crystal Johnson, and Nancy Collins reported discomfort due to the beds. Tammy Benson DVM and Crystal Johnson mentioned that the uncomfortable beds made it difficult to get a good night's sleep during their stay. Nancy Collins also pointed out that the outdated and uncomfortable beds affected her overall comfort, despite the hospital having knowledgeable doctors and a clean environment.\")]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospital_agent_executor.invoke(\n",
    "    {\"input\": \"What have patients said about their comfort at the hospital?\"}\n",
    " )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
